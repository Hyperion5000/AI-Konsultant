# AI-Konsultant (Telegram RAG Bot)

Юридический ИИ-консультант в Telegram, работающий локально с использованием RAG (Retrieval-Augmented Generation). Бот отвечает на вопросы пользователей, основываясь на загруженных документах (законах, договорах и т.д.).

## Особенности

- **Локальная работа**: Использует Ollama (Qwen 2.5) для генерации ответов и ChromaDB для хранения базы знаний.
- **RAG**: Поиск релевантных фрагментов документов для формирования точного ответа.
- **Источники**: Указывает названия документов и части текста, на основе которых дан ответ.
- **Конфигурируемость**: Все настройки вынесены в `.env`.
- **Безопасность**: Защита от prompt injection, фильтрация нерелевантных запросов.

## Требования

- Python 3.12+
- [Ollama](https://ollama.com/) (установленный и запущенный)
- Минимум 8-16 ГБ RAM (для работы LLM и эмбеддингов)

## Установка

1. **Клонируйте репозиторий:**
   ```bash
   git clone https://github.com/Hyperion5000/AI-Konsultant.git
   cd AI-Konsultant
   ```

2. **Установите зависимости:**
   Проект использует `uv` для управления зависимостями.
   ```bash
   pip install uv
   uv sync
   ```
   Или используйте `pip`:
   ```bash
   pip install -r requirements.txt
   ```
   *(Примечание: `requirements.txt` нужно сгенерировать, если вы не используете `uv`)*

3. **Настройте переменные окружения:**
   Скопируйте пример файла конфигурации:
   ```bash
   cp .env.example .env
   ```
   Отредактируйте `.env`, указав ваш токен Telegram бота:
   ```ini
   BOT_TOKEN=ващ_токен_здесь
   ```
   Остальные настройки можно оставить по умолчанию.

4. **Загрузите модель в Ollama:**
   ```bash
   ollama pull qwen2.5:7b
   ```
   (Вы можете использовать другую модель, изменив `OLLAMA_MODEL` в `.env`)

## Создание базы знаний

Перед запуском бота необходимо создать индекс документов.

1. Поместите ваши документы (`.docx`, `.txt`, `.md`) в папку `data/`.
2. Запустите скрипт индексации:
   ```bash
   uv run python create_index.py
   ```
   Или с дополнительными параметрами:
   ```bash
   uv run python create_index.py --input my_docs --persist-dir db --chunk-size 1000
   ```

## Запуск бота

```bash
uv run python main.py
```

## Использование

- `/start` - Приветствие и описание возможностей.
- `/help` - Справка.
- `/reset` - Очистить контекст диалога (начать новую тему).
- Отправьте текстовое сообщение с вопросом, и бот ответит, используя базу знаний.

## Конфигурация (.env)

| Параметр | Описание | Значение по умолчанию |
|---|---|---|
| `BOT_TOKEN` | Токен Telegram бота | (Обязательно) |
| `EMBEDDING_MODEL` | Модель для эмбеддингов (HuggingFace) | `cointegrated/rubert-tiny2` |
| `OLLAMA_BASE_URL` | URL API Ollama | `http://localhost:11434` |
| `OLLAMA_MODEL` | LLM модель в Ollama | `qwen2.5:7b` |
| `CHROMA_DIR` | Папка для базы ChromaDB | `db` |
| `RETRIEVER_K` | Количество извлекаемых фрагментов | `4` |
| `TEMPERATURE` | Температура генерации (креативность) | `0.3` |
| `MAX_DISTANCE` | Порог релевантности (дистанция). Если `None`, проверка отключена. | `None` (отключено) |
| `LLM_CONCURRENCY` | Лимит одновременных генераций LLM | `1` |

## Troubleshooting

- **Error: Database directory db not found.**
  Запустите `create_index.py` перед запуском бота.

- **Ollama connection failed**
  Убедитесь, что Ollama запущена (`ollama serve`) и доступна по адресу `OLLAMA_BASE_URL`.

- **Бот отвечает долго**
  Генерация на CPU может занимать время. Попробуйте уменьшить размер контекста (`RETRIEVER_K`) или использовать более легкую модель (например, `qwen2.5:1.5b`).

- **Бот отвечает "В базе не найдено..."**
  Попробуйте переформулировать вопрос или проверьте, есть ли соответствующая информация в документах в папке `data/`. Также можно попробовать увеличить `MAX_DISTANCE` или отключить его.

## Тестирование

Для запуска тестов:
```bash
uv run pytest
```
